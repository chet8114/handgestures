# ğŸ– Gesture Controlled Media Player (AI Web App)

An AI-powered web application that allows users to control their media player using simple hand gestures captured through a webcam.
This project combines Computer Vision and Humanâ€“Computer Interaction to provide a futuristic, touch-free way to control media playback.

---

## ğŸš€ Features

* Real-time hand tracking using webcam
* Finger counting with MediaPipe
* Gesture-based control of:

  * â–¶ Play / Pause
  * ğŸ”Š Volume Up
  * ğŸ”‰ Volume Down
  * â© Forward
  * âª Backward
* Live camera feed inside a web browser
* Beautiful modern UI built with Streamlit
* Gesture icons and visual feedback
* Smooth, non-glitchy gesture detection
* Contactless media control

---

## ğŸ§  How It Works

The application uses **MediaPipe Hands** to detect hand landmarks from the webcam feed.
The number of raised fingers is calculated from the landmarks, and a corresponding media action is triggered using **PyAutoGUI** to control the systemâ€™s media keys.

To avoid accidental toggling, the Play/Pause gesture works only when the hand is closed first and then opened.

### âœ‹ Gesture Mapping

| Gesture      | Action       |
| ------------ | ------------ |
| âœŠ 0 Fingers  | Reset        |
| â˜ï¸ 1 Finger  | Play / Pause |
| âœŒï¸ 2 Fingers | Volume Up    |
| ğŸ¤Ÿ 3 Fingers | Volume Down  |
| ğŸ– 4 Fingers | Forward      |
| âœ‹ 5 Fingers  | Backward     |

---

## ğŸ›  Tech Stack

* **Python**
* **OpenCV** â€“ Camera and image processing
* **MediaPipe** â€“ Hand landmark detection
* **PyAutoGUI** â€“ System media key control
* **Streamlit** â€“ Web UI and app framework

---

## ğŸ“‚ Project Structure

Only the necessary project files are included in the repository.

```
gesture-media-control/
â”‚
â”œâ”€â”€ app.py             # Main Streamlit application
â”œâ”€â”€ style.css          # Custom UI styling
â”œâ”€â”€ requirements.txt  # Python dependencies
â”œâ”€â”€ .gitignore         # Files and folders ignored by Git
â””â”€â”€ README.md
```

> âš ï¸ The virtual environment (`venv/`) is intentionally not included.
> It is recreated locally using `requirements.txt`.

---

## â–¶ How to Run Locally

1. Clone the repository:

```bash
git clone https://github.com/yourusername/your-repo-name.git
cd your-repo-name
```

2. Create a virtual environment (recommended):

```bash
python -m venv venv
venv\Scripts\activate   # Windows
```

3. Install dependencies:

```bash
pip install -r requirements.txt
```

4. Run the app:

```bash
streamlit run app.py
```

5. Open the browser and allow camera access.

---

## ğŸŒ Deployment (Free)

This app can be deployed on **Streamlit Cloud**.

Steps:

1. Push this repository to GitHub
2. Go to [https://share.streamlit.io](https://share.streamlit.io)
3. Sign in with GitHub
4. Select this repository
5. Choose `app.py` as the main file
6. Click **Deploy**

You will get a public link to share your live AI app.

---

## ğŸ¯ Use Cases

* Touch-free media control
* Smart TV and PC interaction
* Accessibility support
* AI-based humanâ€“computer interaction
* Computer vision demos

---

## ğŸ‘¨â€ğŸ’» Author

**Chethan**
Computer Science Engineer | AI & Computer Vision Enthusiast

This project was built to demonstrate real-time AI-powered gesture control using modern computer vision techniques.

